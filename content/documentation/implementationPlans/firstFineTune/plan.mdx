# Fine-Tune Project Plan

[[./implementation-plan]]

## Big Picture

The goal is to create a Supervised Fine-Tuning (SFT) model that demonstrably
performs better than the stock GPT-3.5-Turbo model. This will serve as proof of
concept for the Bolt Foundry platform's fine-tuning capabilities.

### Identity Card vs. Behavior Card

It's important to distinguish between two separate concepts in our approach:

1. **Identity Card** - Used for Direct Preference Optimization (DPO)
   - Focuses on the model's identity, values, and decision-making preferences
   - This is out of scope for the current implementation

2. **Behavior Card** - Used for Supervised Fine-Tuning (SFT)
   - Focuses on specific behaviors we want to train the model to perform consistently
   - In this case, reliably producing valid JSON output
   - This is what we're attempting to build in the current implementation

## Phase 1: Foundation Setup and Data Collection (Core)

### Goals

1. Setup infrastructure for fine-tuning
2. Define evaluation metrics
3. Collect initial training and evaluation data

### Implementation Steps

1. **Define the fine-tuning objective: Consistent JSON Output**
   - Primary goal: Train the model to output valid, well-structured JSON 100% of
     the time
   - Secondary goals: Maintain accurate information while ensuring JSON
     structure is never broken
   - Document the objective specifications in
     `packages/bolt-foundry/docs/firstFineTune/objectives.md`

2. **Create JSON validation evaluation mechanism**
   - Implement automated JSON validation for all model outputs
   - Create metrics tracking:
     - JSON validity rate (%)
     - Schema conformity rate (for outputs with expected schemas)
     - Error types and frequency (missing brackets, invalid escaping, etc.)
     - Performance comparison between base and fine-tuned models
   - Build on existing functionality in `packages/bolt-foundry/bolt-foundry.ts`
     for model redirection and testing

3. **Data collection framework**
   - Create a structured way to store training examples:
     ```typescript
     type TrainingExample = {
       id: string;
       prompt: string;
       completion: string;
       metadata?: {
         source?: string;
         quality?: number; // rating from 1-5
         tags?: string[];
         jsonSchema?: object; // Optional JSON schema that the completion should conform to
       };
     };
     ```
   - Implement storage in `packages/bolt-foundry/finetune/dataCollection.ts`

4. **Initial dataset creation**
   - Generate/collect 200-300 high-quality training examples of various JSON
     outputs:
     - Simple JSON objects with different property types
     - Nested JSON structures
     - Arrays of objects
     - Edge cases (empty objects, single properties, etc.)
   - Ensure examples include diverse prompts that might typically cause JSON
     errors:
     - Requests for complex or ambiguous data
     - Multi-step instructions
     - Requests with conflicting requirements
   - Store in a structured format in `content/firstFineTune/trainingData/`

## Phase 2: Fine-Tuning Pipeline

### Goals

1. Create a reproducible fine-tuning pipeline
2. Implement data preprocessing
3. Configure and execute the fine-tuning job

### Implementation Steps

1. **Data preprocessing**
   - Create tools to convert collected examples into OpenAI's fine-tuning format
   - Implement validation to ensure data quality
   - Add in `packages/bolt-foundry/finetune/dataPreprocessing.ts`

2. **Fine-tuning job configuration**
   - Create a configuration interface for fine-tuning parameters
   - Implement in `packages/bolt-foundry/finetune/fineTuneConfig.ts`

3. **Fine-tuning execution**
   - Build a wrapper around OpenAI's fine-tuning API
   - Include job monitoring and status updates
   - Implement in `packages/bolt-foundry/finetune/fineTuneJob.ts`

4. **Model versioning**
   - Create a system to track and reference different fine-tuned models
   - Store metadata about each model (training data used, parameters, etc.)
   - Implement in `packages/bolt-foundry/finetune/modelRegistry.ts`

## Phase 3: Evaluation and Testing

### Goals

1. Establish rigorous JSON validation methodology
2. Compare base and fine-tuned models
3. Document improvements and limitations

### Implementation Steps

1. **JSON Evaluation framework**
   - Create evaluation datasets specifically designed to challenge JSON
     generation:
     - Complex nested structures
     - Edge cases (special characters, very long strings, etc.)
     - Ambiguous requests
   - Implement automated JSON validation scripts:
     - JSON syntax validation
     - Schema conformity checking
     - Content accuracy evaluation
   - Track failure modes and categorize error types
   - Implement in `packages/bolt-foundry/finetune/evaluation/jsonValidator.ts`

2. **A/B testing functionality**
   - Create functionality to split traffic between base and fine-tuned models
   - Implement result collection and comparison
   - Build on the existing model routing in
     `packages/bolt-foundry/bolt-foundry.ts`

3. **Performance analysis dashboard**
   - Create a simple UI to visualize evaluation results
   - Compare metrics between base and fine-tuned models
   - Implement in `packages/bolt-foundry/finetune/dashboard/`

4. **Documentation generation**
   - Automatically generate reports on model performance
   - Document limitations and potential improvements
   - Implement in `packages/bolt-foundry/finetune/reporting.ts`

## Phase 4: Iteration and Improvement

### Goals

1. Refine the fine-tuning based on evaluation results
2. Implement a feedback loop for continuous improvement
3. Scale up successful approaches

### Implementation Steps

1. **Feedback collection system**
   - Create a mechanism to collect feedback on model outputs
   - Store and analyze feedback for future iterations
   - Implement in `packages/bolt-foundry/finetune/feedback/`

2. **Dataset refinement**
   - Use feedback to improve training data
   - Identify and address gaps in the dataset
   - Update in `packages/bolt-foundry/finetune/dataRefinement.ts`

3. **Experimentation framework**
   - Create a system to run experiments with different fine-tuning parameters
   - Compare results and identify optimal configurations
   - Implement in `packages/bolt-foundry/finetune/experiments.ts`

## Implementation Details

### JSON-Specific Training Strategy

To effectively train the model for consistent JSON output, we'll implement the
following specialized approaches:

1. **Systematic Example Creation**
   - Create examples that systematically cover the JSON specification
   - Include examples handling edge cases like escape characters, unicode, and
     deeply nested structures
   - Develop prompts that explicitly request JSON and others that implicitly
     require JSON

2. **Error Correction Examples**
   - Include examples where the model is shown common JSON errors and how to fix
     them
   - Train the model to recognize and avoid typical JSON pitfalls (unclosed
     brackets, missing quotes, trailing commas)

3. **Schema Enforcement**
   - Include examples of following specific JSON schemas
   - Train the model to validate its own output against provided schemas

4. **Robust System Messages**
   - Develop standard system messages that reinforce JSON output requirements
   - Test variations to find optimal phrasing for ensuring JSON compliance

5. **Progressive Complexity**
   - Structure training data to progress from simple to complex JSON structures
   - Ensure coverage across different JSON patterns (objects, arrays, nested
     combinations)

### Test-Driven Development Approach

Following the TDD principles from AGENT.md, each implementation phase should
begin with tests that define the expected behavior:

```typescript
// Example test for JSON validation
Deno.test("JSON validator should correctly identify valid and invalid JSON", async () => {
  const mockCv = BfCurrentViewer.__DANGEROUS__createTestCurrentViewer(
    import.meta,
    true,
  );

  // Setup test responses
  const responses = [
    {
      id: "valid1",
      content: '{"name": "John", "age": 30, "city": "New York"}',
      expectedValidity: true,
    },
    {
      id: "invalid1",
      content: '{"name": "John", "age": 30, "city": "New York",}', // trailing comma
      expectedValidity: false,
    },
    {
      id: "invalid2",
      content: '{"name": "John", "age": 30, "city": "New York"', // missing closing brace
      expectedValidity: false,
    },
  ];

  // Test the JSON validation function
  for (const response of responses) {
    const result = await validateJson(mockCv, response.content);
    assertEquals(result.isValid, response.expectedValidity);
    if (!response.expectedValidity) {
      assertExists(result.errorType);
    }
  }
});

// Example test for schema validation
Deno.test("Schema validator should check JSON against provided schema", async () => {
  const mockCv = BfCurrentViewer.__DANGEROUS__createTestCurrentViewer(
    import.meta,
    true,
  );

  const schema = {
    type: "object",
    required: ["name", "items"],
    properties: {
      name: { type: "string" },
      items: {
        type: "array",
        items: { type: "string" },
      },
    },
  };

  const validJson =
    '{"name": "Shopping List", "items": ["Milk", "Eggs", "Bread"]}';
  const invalidJson = '{"name": "Shopping List", "items": [1, 2, 3]}'; // numbers instead of strings

  const validResult = await validateJsonAgainstSchema(
    mockCv,
    validJson,
    schema,
  );
  const invalidResult = await validateJsonAgainstSchema(
    mockCv,
    invalidJson,
    schema,
  );

  assertEquals(validResult.conformsToSchema, true);
  assertEquals(invalidResult.conformsToSchema, false);
});
```

### Integration with Existing Code

This plan builds on the existing `bolt-foundry` package, which already:

1. Overrides OpenAI API requests
2. Modifies model parameters
3. Handles authentication

The new fine-tuning functionality will integrate with this foundation, extending
it to support:

1. Creating and managing fine-tuned models
2. Routing requests to appropriate models
3. Evaluating and comparing model performance

### Data Architecture

The fine-tuning data will be stored in a structured format:

```
content/
  firstFineTune/
    trainingData/      # Raw training examples
    processedData/     # Processed data ready for fine-tuning
    evaluationData/    # Data for evaluating models
    models/            # Information about fine-tuned models
    results/           # Evaluation results and comparisons
```

## Technical Requirements

- OpenAI API access with fine-tuning capabilities
- Storage for training and evaluation data (local file system initially)
- Processing capacity for data preparation and evaluation

## Success Criteria

A successful first fine-tune project will:

1. Produce a fine-tuned model that achieves at least 98% JSON validity (compared
   to the base model's typical performance)
2. Reduce JSON structure errors by at least 90% compared to the base model
3. Maintain or improve the quality and accuracy of the content within the JSON
4. Maintain performance on non-JSON tasks (to ensure we haven't degraded general
   capabilities)
5. Establish a reproducible pipeline for future fine-tuning projects
6. Demonstrate the value of the Bolt Foundry platform for creating reliable,
   format-consistent AI outputs