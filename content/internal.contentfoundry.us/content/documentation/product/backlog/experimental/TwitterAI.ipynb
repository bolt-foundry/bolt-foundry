{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98bf022a-e48f-4dc9-9292-1bd2e04cd49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36m<ref *1>\u001b[39m OpenAI {\n",
       "  baseURL: \u001b[32m\"https://openrouter.ai/api/v1\"\u001b[39m,\n",
       "  maxRetries: \u001b[33m2\u001b[39m,\n",
       "  timeout: \u001b[33m600000\u001b[39m,\n",
       "  httpAgent: \u001b[90mundefined\u001b[39m,\n",
       "  fetch: \u001b[36m[Function: fetch]\u001b[39m,\n",
       "  idempotencyHeader: \u001b[90mundefined\u001b[39m,\n",
       "  apiKey: \u001b[32m\"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\"\u001b[39m,\n",
       "  organization: \u001b[1mnull\u001b[22m,\n",
       "  project: \u001b[1mnull\u001b[22m,\n",
       "  _options: {\n",
       "    apiKey: \u001b[32m\"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\"\u001b[39m,\n",
       "    organization: \u001b[1mnull\u001b[22m,\n",
       "    project: \u001b[1mnull\u001b[22m,\n",
       "    baseURL: \u001b[32m\"https://openrouter.ai/api/v1\"\u001b[39m\n",
       "  },\n",
       "  completions: Completions { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  chat: Chat {\n",
       "    _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "    completions: Completions { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "  },\n",
       "  embeddings: Embeddings { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  files: Files { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  images: Images { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  audio: Audio {\n",
       "    _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "    transcriptions: Transcriptions { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "    translations: Translations { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "    speech: Speech { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "  },\n",
       "  moderations: Moderations { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  models: Models { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  fineTuning: FineTuning {\n",
       "    _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "    jobs: Jobs {\n",
       "      _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "      checkpoints: Checkpoints { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  beta: Beta {\n",
       "    _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "    realtime: Realtime {\n",
       "      _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "      sessions: Sessions { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "    },\n",
       "    vectorStores: VectorStores {\n",
       "      _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "      files: Files { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "      fileBatches: FileBatches { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "    },\n",
       "    chat: Chat {\n",
       "      _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "      completions: Completions { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "    },\n",
       "    assistants: Assistants { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "    threads: Threads {\n",
       "      _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "      runs: Runs {\n",
       "        _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "        steps: Steps { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "      },\n",
       "      messages: Messages { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  batches: Batches { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  uploads: Uploads {\n",
       "    _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "    parts: Parts { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { getAi } from \"lib/ai.ts\";\n",
    "import { z } from \"zod\";\n",
    "import { zodResponseFormat } from \"openai/helpers/zod\";\n",
    "import { getLogger } from \"packages/logger.ts\";\n",
    "import { isValidJSON } from \"lib/jsonUtils.ts\";\n",
    "\n",
    "const Schema = z.object({\n",
    " voiceSummary: z.string().describe(\"3 to 5 adjectives describing the persons voice based on their tweets and info\"),\n",
    " voice: z.string().describe(\"a description of the persons voice based on their tweets and info. Perhaps compare their voice to an influencial person on twitter with evidence to support it.\"),\n",
    "});\n",
    "\n",
    "const openAi = getAi();\n",
    "\n",
    "export default openAi;\n",
    "\n",
    "export const systemPrompty =\n",
    "  `You are an assistant who analyzes a persons twitter profile and tweets in order to give them a summary of their voice on twitter\n",
    "`;\n",
    "\n",
    "const taskPrompty =\n",
    "  `Here is my twitter handle, please analyze my profile by searching the web for it and give me tell me about my voice\n",
    "`;\n",
    "\n",
    "export async function runIt(\n",
    "  content: string,\n",
    "  taskPrompt = taskPrompty,\n",
    "  systemPrompt = systemPrompty,\n",
    ") {\n",
    "  const options = {};\n",
    "  const response = await openAi.chat.completions.create(\n",
    "    {\n",
    "      model: \"openai/gpt-4o:online\",\n",
    "      response_format: zodResponseFormat(Schema, \"schema\"),\n",
    "      temperature: .2,\n",
    "      messages: [\n",
    "        {\n",
    "          role: \"system\",\n",
    "          content: systemPrompt,\n",
    "        },\n",
    "        {\n",
    "          role: \"system\",\n",
    "          content: taskPrompt,\n",
    "        },\n",
    "        {\n",
    "          role: \"user\",\n",
    "          content,\n",
    "        },\n",
    "        {\n",
    "          role: \"system\",\n",
    "          content:\n",
    "            \"Please return results for the voice using our  JSON schema.\",\n",
    "        },\n",
    "      ],\n",
    "    },\n",
    "    options,\n",
    "  );\n",
    "\n",
    "  const choice = response.choices[0];\n",
    "  if (!choice) throw new Error(\"No choice\");\n",
    "  let responseObject = {};\n",
    "  try {\n",
    "    responseObject = isValidJSON(choice.message.content ?? \"{}\")\n",
    "      ? JSON.parse(choice.message.content ?? \"{}\")\n",
    "      : {};\n",
    "    return responseObject;\n",
    "  } catch (e) {\n",
    "    return responseObject;\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e6f3f6d-775e-447d-9547-fed3fa3d7ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36m<ref *1>\u001b[39m OpenAI {\n",
       "  baseURL: \u001b[32m\"https://openrouter.ai/api/v1\"\u001b[39m,\n",
       "  maxRetries: \u001b[33m2\u001b[39m,\n",
       "  timeout: \u001b[33m600000\u001b[39m,\n",
       "  httpAgent: \u001b[90mundefined\u001b[39m,\n",
       "  fetch: \u001b[36m[Function: fetch]\u001b[39m,\n",
       "  idempotencyHeader: \u001b[90mundefined\u001b[39m,\n",
       "  apiKey: \u001b[32m\"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\"\u001b[39m,\n",
       "  organization: \u001b[1mnull\u001b[22m,\n",
       "  project: \u001b[1mnull\u001b[22m,\n",
       "  _options: {\n",
       "    apiKey: \u001b[32m\"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\"\u001b[39m,\n",
       "    organization: \u001b[1mnull\u001b[22m,\n",
       "    project: \u001b[1mnull\u001b[22m,\n",
       "    baseURL: \u001b[32m\"https://openrouter.ai/api/v1\"\u001b[39m\n",
       "  },\n",
       "  completions: Completions { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  chat: Chat {\n",
       "    _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "    completions: Completions { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "  },\n",
       "  embeddings: Embeddings { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  files: Files { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  images: Images { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  audio: Audio {\n",
       "    _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "    transcriptions: Transcriptions { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "    translations: Translations { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "    speech: Speech { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "  },\n",
       "  moderations: Moderations { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  models: Models { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  fineTuning: FineTuning {\n",
       "    _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "    jobs: Jobs {\n",
       "      _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "      checkpoints: Checkpoints { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  beta: Beta {\n",
       "    _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "    realtime: Realtime {\n",
       "      _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "      sessions: Sessions { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "    },\n",
       "    vectorStores: VectorStores {\n",
       "      _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "      files: Files { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "      fileBatches: FileBatches { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "    },\n",
       "    chat: Chat {\n",
       "      _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "      completions: Completions { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "    },\n",
       "    assistants: Assistants { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "    threads: Threads {\n",
       "      _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "      runs: Runs {\n",
       "        _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "        steps: Steps { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "      },\n",
       "      messages: Messages { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  batches: Batches { _client: \u001b[36m[Circular *1]\u001b[39m },\n",
       "  uploads: Uploads {\n",
       "    _client: \u001b[36m[Circular *1]\u001b[39m,\n",
       "    parts: Parts { _client: \u001b[36m[Circular *1]\u001b[39m }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { getAi } from \"lib/ai.ts\";\n",
    "import { z } from \"zod\";\n",
    "import { zodResponseFormat } from \"openai/helpers/zod\";\n",
    "import { getLogger } from \"packages/logger.ts\";\n",
    "import { isValidJSON } from \"lib/jsonUtils.ts\";\n",
    "\n",
    "const TweetSuggestionSchema = z.object({\n",
    "  tweet: z.string().describe(\"a revised version of the given tweet better suited to fit the users voice, avoiding hashtags if the user doesn't use them\"),\n",
    "  explanation: z.string().describe(\"an explination of the revisions made\"),\n",
    "});\n",
    "\n",
    "const Schema = z.object({\n",
    "  tweetsuggestions: z.array(TweetSuggestionSchema).describe(\"an array of 5 objects that match the given schema\")\n",
    "});\n",
    "\n",
    "const openAi = getAi();\n",
    "\n",
    "export default openAi;\n",
    "\n",
    "export const systemPrompty =\n",
    "  `You are an assistant suggests alternative tweets that are more in line with a persons existing voice on twitter.\n",
    "`;\n",
    "\n",
    "const taskPrompty =\n",
    "  `here is my draft tweet and a description of my voice.\n",
    "`;\n",
    "\n",
    "export async function makeNewTweets(\n",
    "  content: string,\n",
    "  taskPrompt = taskPrompty,\n",
    "  systemPrompt = systemPrompty,\n",
    ") {\n",
    "  const options = {};\n",
    "  const response = await openAi.chat.completions.create(\n",
    "    {\n",
    "      model: \"openai/gpt-4o:online\",\n",
    "      response_format: zodResponseFormat(Schema, \"schema\"),\n",
    "      temperature: .2,\n",
    "      messages: [\n",
    "        {\n",
    "          role: \"system\",\n",
    "          content: systemPrompt,\n",
    "        },\n",
    "        {\n",
    "          role: \"system\",\n",
    "          content: taskPrompt,\n",
    "        },\n",
    "        {\n",
    "          role: \"user\",\n",
    "          content,\n",
    "        },\n",
    "        {\n",
    "          role: \"system\",\n",
    "          content:\n",
    "            \"Please return the new tweets using our  JSON schema.\",\n",
    "        },\n",
    "      ],\n",
    "    },\n",
    "    options,\n",
    "  );\n",
    "\n",
    "  const choice = response.choices[0];\n",
    "  if (!choice) throw new Error(\"No choice\");\n",
    "  let responseObject = {};\n",
    "  try {\n",
    "    responseObject = isValidJSON(choice.message.content ?? \"{}\")\n",
    "      ? JSON.parse(choice.message.content ?? \"{}\")\n",
    "      : {};\n",
    "    return responseObject;\n",
    "  } catch (e) {\n",
    "    return responseObject;\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7293a2a5-dffb-4033-b349-c081c5f7a0cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "401 No auth credentials found",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: 401 No auth credentials found",
      "    at Function.generate (https://jsr.io/@openai/openai/4.79.1/error.ts:76:14)",
      "    at OpenAI.makeStatusError (https://jsr.io/@openai/openai/4.79.1/core.ts:435:21)",
      "    at OpenAI.makeRequest (https://jsr.io/@openai/openai/4.79.1/core.ts:499:24)",
      "    at eventLoopTick (ext:core/01_core.js:177:7)",
      "    at async runIt (<anonymous>:18:20)",
      "    at async <anonymous>:1:22"
     ]
    }
   ],
   "source": [
    "await runIt(\"@randallb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e40d78-523d-40f1-b6a4-9b950698f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "const voice = {\n",
    "  voiceSummary: \"reflective, resilient, candid, entrepreneurial, insightful\",\n",
    "  voice: `Randall Bennett's voice on Twitter is reflective and resilient, often sharing personal and professional experiences that highlight his journey through challenges and successes. His tweets convey a candid and entrepreneurial spirit, as he openly discusses the ups and downs of startup life. For example, in a tweet, he shares, \"My dad died, my company almost died, and then we got bought by Facebook. All within 6 months. @paulg's 'how to not die' is right. If you don't die long enough, your startup will make you rich. But you have to be humble for that to work\" ([x.com](https://x.com/randallb?lang=en)). This tweet exemplifies his ability to draw insights from personal hardships and professional milestones, offering a narrative that is both personal and universally relatable to those in the entrepreneurial space.`\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a062e19-63c7-4191-a47e-8e9daa7ddca3",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "401 No auth credentials found",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: 401 No auth credentials found",
      "    at Function.generate (https://jsr.io/@openai/openai/4.79.1/error.ts:76:14)",
      "    at OpenAI.makeStatusError (https://jsr.io/@openai/openai/4.79.1/core.ts:435:21)",
      "    at OpenAI.makeRequest (https://jsr.io/@openai/openai/4.79.1/core.ts:499:24)",
      "    at eventLoopTick (ext:core/01_core.js:177:7)",
      "    at async makeNewTweets (<anonymous>:21:20)",
      "    at async <anonymous>:1:22"
     ]
    }
   ],
   "source": [
    "await makeNewTweets(`Hey everybody! I sure love being a startup founder, ${JSON.stringify(voice)}`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
